{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from phimal_utilities.data import Dataset\n",
    "from phimal_utilities.data.burgers import BurgersDelta\n",
    "from DeePyMoD_SBL.deepymod_torch.library_functions import library_1D_in\n",
    "from DeePyMoD_SBL.deepymod_torch.DeepMod import DeepMod, DeepModDynamic\n",
    "from DeePyMoD_SBL.deepymod_torch.output import Tensorboard, progress\n",
    "from DeePyMoD_SBL.deepymod_torch.losses import reg_loss, mse_loss, l1_loss\n",
    "from DeePyMoD_SBL.deepymod_torch.sparsity import scaling, threshold\n",
    "from sklearn.linear_model import LassoLarsIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of grid: (512, 201)\n"
     ]
    }
   ],
   "source": [
    "data = np.load('kdv.npy', allow_pickle=True).item()\n",
    "print('Shape of grid:', data['x'].shape)\n",
    "X = np.transpose((data['t'].flatten(), data['x'].flatten()))\n",
    "y = np.real(data['u']).reshape((data['u'].size, 1))\n",
    "x_grid, t_grid = np.meshgrid(data['x'][:,0], data['t'][0], indexing='ij')\n",
    "noise_level = 0.05\n",
    "y_noisy = y + noise_level * np.std(y) * np.random.randn(y[:,0].size, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 5000\n",
    "\n",
    "idx = np.random.permutation(y.shape[0])\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(y_noisy[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training function\n",
    "def train(model, data, target, optimizer, max_iterations, loss_func_args, log_dir=None):\n",
    "    start_time = time.time()\n",
    "    number_of_terms = [coeff_vec.shape[0] for coeff_vec in model(data)[3]]\n",
    "    board = Tensorboard(number_of_terms, log_dir)\n",
    "    \n",
    "    # Training\n",
    "    print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       LL |')\n",
    "    for iteration in torch.arange(0, max_iterations + 1):\n",
    "        # Calculating prediction and library and scaling\n",
    "        prediction, time_deriv_list, sparse_theta_list, coeff_vector_list, theta = model(data)\n",
    "        coeff_vector_scaled_list = scaling(coeff_vector_list, sparse_theta_list, time_deriv_list) \n",
    "        \n",
    "        # Calculating loss\n",
    "        loss_mse = mse_loss(prediction, target)\n",
    "        loss_reg = reg_loss(time_deriv_list, sparse_theta_list, coeff_vector_list)\n",
    "        loss_ll = torch.log(2 * pi * loss_mse)\n",
    "        loss_ll_fit = torch.log(2 * pi * loss_mse) + loss_reg / loss_mse\n",
    "        loss = torch.sum(loss_ll) + torch.sum(loss_ll_fit)\n",
    "        \n",
    "        # Writing\n",
    "        if iteration % 100 == 0:\n",
    "            # Write progress to command line\n",
    "            progress(iteration, start_time, max_iterations, loss.item(), torch.sum(loss_mse).item(), torch.sum(loss_reg).item(), torch.sum(loss_ll).item())\n",
    "            \n",
    "            lstsq_solution = torch.inverse(theta.T @ theta) @ theta.T @ time_deriv_list[0]\n",
    "            \n",
    "            # Calculate error for theta\n",
    "        \n",
    "            \n",
    "            # Write to tensorboard\n",
    "            board.write(iteration, loss, loss_mse, loss_reg, loss_ll, coeff_vector_list, coeff_vector_scaled_list, log_likelihood=loss_ll, ll_fit=loss_ll_fit, lstsq_solution=lstsq_solution.squeeze())\n",
    "\n",
    "        # Optimizer step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    board.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = dataset.library(x_grid.reshape(-1, 1), t_grid.reshape(-1, 1), poly_order=2, deriv_order=3)[rand_idx, :]\n",
    "dt = dataset.time_deriv(x_grid.reshape(-1, 1), t_grid.reshape(-1, 1))[rand_idx, :]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepMod(**config)\n",
    "optimizer = torch.optim.Adam(model.parameters(), betas=(0.99, 0.999), amsgrad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       LL |\n",
      "      20000    100.00%               0s   -1.72e+01   2.90e-05   4.48e-07   -8.61e+00 "
     ]
    }
   ],
   "source": [
    "train(model, X_train, y_train, optimizer, 20000, loss_func_args={'library':torch.tensor(theta) ,'time_deriv': torch.tensor(dt)}, log_dir = f'runs/deepmod_logprob_run_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
