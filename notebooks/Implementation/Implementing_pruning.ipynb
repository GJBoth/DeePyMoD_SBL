{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we implement an easier library layer, a regression layer and the pruning with pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Remainder imports\n",
    "from os import listdir, path, getcwd\n",
    "\n",
    "# Setting cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Defining output folder\n",
    "output_folder = getcwd()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# DeepMoD stuff\n",
    "from deepymod_torch.utilities import create_deriv_data\n",
    "from deepymod_torch.network import Linear, Tanh\n",
    "from deepymod_torch.output import progress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing new layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a simpler library layer for now use in the network. Let's not worry about deepmod for now and just make it easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Library(nn.Module):\n",
    "    '''Abstract baseclass for library-as-layer. Child requires theta function (see library_functions). '''\n",
    "    def __init__(self, input_dim, output_dim, diff_order):\n",
    "        super().__init__()\n",
    "        self.diff_order = diff_order\n",
    "        self.total_terms = self.terms(input_dim, output_dim, self.diff_order)\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''Calculates output.'''\n",
    "        time_deriv_list, theta = self.theta(input)\n",
    "        return input, time_deriv_list, theta\n",
    "\n",
    "    def terms(self, input_dim, output_dim, max_order):\n",
    "        '''Calculates the number of terms the library produces'''\n",
    "        sample_data = (torch.ones((1, output_dim), dtype=torch.float32), torch.ones((1, max_order, input_dim, output_dim), dtype=torch.float32)) # we run a single forward pass on fake data to infer shapes\n",
    "        total_terms = self.theta(sample_data)[1].shape[1]\n",
    "\n",
    "        return total_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class library_basic(Library):\n",
    "    '''Implementation of library layer. Inherets from Library layer.'''\n",
    "    def __init__(self, input_dim, output_dim, diff_order, poly_order):\n",
    "        self.poly_order = poly_order\n",
    "        super().__init__(input_dim, output_dim, diff_order)\n",
    "    \n",
    "    def theta(self, input):\n",
    "        '''Calculates the library and time deriv from NN output'''\n",
    "        X, dX = input\n",
    "        samples = X.shape[0]\n",
    "\n",
    "        # Time derivatives\n",
    "        dt = dX[:, 0, :1, :]\n",
    "        time_deriv_list = torch.unbind(dt, dim=2)\n",
    "\n",
    "        # Polynomial part\n",
    "        u = torch.ones_like(X)[:, None, :]\n",
    "        for order in torch.arange(1, self.poly_order+1):\n",
    "            u = torch.cat((u, u[:, order-1:order, :] * X[:, None, :]), dim=1)\n",
    "        poly_list = torch.unbind(u, dim=2) #list with each entry corresponding to eq.\n",
    "\n",
    "        # Derivative part\n",
    "        dx = dX[:, :, 1:, :]\n",
    "        deriv_list = [torch.cat((torch.ones((samples, 1)), eq.reshape(samples, -1)), dim=1) for eq in torch.unbind(dx, dim=3)] #list with each entry corresponding to eq.\n",
    "        \n",
    "        # Combining to make  theta\n",
    "        if len(poly_list) == 1:\n",
    "            theta = torch.matmul(poly_list[0][:, :, None], deriv_list[0][:, None, :]).reshape(samples, -1) # If we have a single output, we simply calculate and flatten matrix product between polynomials and derivatives to get library\n",
    "        else:\n",
    "            theta_uv = torch.cat([torch.matmul(u[:, :, None], v[:, None, :]).reshape(samples, -1) for u, v in combinations(poly_list, 2)], 1)  # calculate all unique combinations between polynomials\n",
    "            theta_dudv = torch.cat([torch.matmul(du[:, :, None], dv[:, None, :]).reshape(samples, -1)[:, 1:] for du, dv in combinations(deriv_list, 2)], 1) # calculate all unique combinations of derivatives\n",
    "            theta_udu = torch.cat([torch.matmul(u[:, 1:, None], du[:, None, 1:]).reshape(samples, -1) for u, du in product(poly_list, deriv_list)], 1)  # calculate all unique products of polynomials and derivatives\n",
    "            theta = torch.cat([theta_uv, theta_dudv, theta_udu], dim=1)\n",
    "\n",
    "        return time_deriv_list, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression layer is a simple linear layer, but we also need to forward the output so let's build a simple wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(nn.Linear):\n",
    "    '''Pytorch style linear layer which also calculates the derivatives w.r.t input. Has been written to be a thin wrapper around the pytorch layer. '''\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__(in_features, out_features, bias=False)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        '''Calculates output'''\n",
    "        z = F.linear(input[2], self.weight)\n",
    "        \n",
    "        return (input, z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(input_dim, hidden_dim, layers, output_dim, library_function, library_args):\n",
    "    ''' Build deepmod model.'''\n",
    "    network = [Linear(input_dim, hidden_dim), Tanh()]  # Input layer\n",
    "    for hidden_layer in torch.arange(layers):  # Hidden layers\n",
    "        network.append(Linear(hidden_dim, hidden_dim))\n",
    "        network.append(Tanh())\n",
    "    network.append(Linear(hidden_dim, output_dim))  # Output layer\n",
    "    \n",
    "    network.append(library_function(input_dim, output_dim, **library_args)) # Library layer\n",
    "    network.append(Regression(network[-1].total_terms, 1)) # Regression layer\n",
    "    torch_network = nn.Sequential(*network)\n",
    "\n",
    "    return torch_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = np.load('../../tests/data/burgers.npy', allow_pickle=True).item()\n",
    "X = np.transpose((data['t'].flatten(), data['x'].flatten()))\n",
    "y = np.real(data['u']).reshape((data['u'].size, 1))\n",
    "number_of_samples = 1500\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "\n",
    "## Running DeepMoD\n",
    "config = {'input_dim': 2, 'hidden_dim': 20, 'layers': 5, 'output_dim': 1, 'library_function': library_basic, 'library_args':{'poly_order': 2, 'diff_order': 2}}\n",
    "\n",
    "X_input = create_deriv_data(X_train, config['library_args']['diff_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_network(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.02 ms ± 10.8 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model(X_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, time to train without l1 and pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "max_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "for iteration in torch.arange(0, max_iterations + 1):\n",
    "    (prediction, time_deriv_list, theta), f = model(X_input)\n",
    "    loss_mse = torch.mean((prediction[0] - y_train)**2)\n",
    "    loss_reg = torch.mean((time_deriv_list[0] - f)**2)\n",
    "    loss = loss_mse + loss_reg\n",
    "        \n",
    "    # Writing\n",
    "    if iteration % 100 == 0:\n",
    "        progress(iteration, 0, max_iterations, loss.item(), loss_mse.item(), loss_reg.item(), 0)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's look at the weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 4.0682e-05,  6.0732e-03,  9.9576e-02,  1.2170e-02, -1.1053e+00,\n",
       "         -2.7602e-02, -3.8416e-02,  2.1788e-01,  1.7072e-02]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[-1].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try and rescale it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_weights = (model[-1].weight * torch.norm(model[:-1](X_input)[2], dim=0)).cpu().detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6590fb9e48>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD7CAYAAABgzo9kAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXs0lEQVR4nO3df2yT97328csOpBttgpM0oabQhHFK5Q0YK3lgPWx0DYEwLSyRphTE6PSUNmiACOuEgJUVGn70zKiCVuFHKjrpaDotQlHXrPlRSBHsnJJndEhDfQhEkIdCQogTQhIEYWhVbT9/oLikAew72PHNl/frLxt/b/tqoBdfPvdt2xEMBoMCABjHGe8AAIDYoOABwFAUPAAYioIHAENR8ABgKAoeAAxFwQOAoYbFO8CtenquKxCwfll+Wtoj6urqjUGie0Mua8hlnV2zkcuaweZyOh1KSXn4jo/bquADgeCgCr7vWDsilzXkss6u2chlTSxyMaIBAENR8ABgKAoeAAwV0Qx+2bJlam1tldPp1IgRI/Taa6/J4/H0W+P3+7V582Z9+umncjgcWrJkiYqKimISGgAQXkQF7/V6lZSUJEk6ePCgXn31VX344Yf91lRVVamlpUV1dXW6cuWKCgsL9cwzz2jMmDHRTw3E2MdHm5XlTpYnMyX0a43NPTrvu6qf/jAzjsmAyEU0oukrd0nq7e2Vw+EYsKa2tlZFRUVyOp1KTU1Vbm6u9u/fH72kwBDKcidrd2WDGpt7JN0s992VDcpyJ8c5GRC5iC+TXLdunerr6xUMBvXuu+8OeNzn82n06NGh+263W+3t7dFJCQwxT2aKlhZO1O7KBrVcvq6aI+e0tHBivx09YHcRF/yWLVskSZWVldq6dav27NkT9TBpaY8M+tj09KTwi+KAXNbYKVd6epJaLl/Xvk/OaP7sCZqZ/US8I92WnX5mtyKXNbHIZfmNToWFhVq/fr16enqUkvL1bsbtdqutrU2TJ0+WNHBHH4murt5BXeyfnp6kzs5rlo+LNXJZY7dcjc09qjlyTvNnT1DNkXN64tGHbbeDt9vPrA+5rBlsLqfTcdeNcdgZ/PXr1+Xz+UL3Dx06pJEjR8rlcvVbN3fuXFVUVCgQCKi7u1sHDx5UXl6e5cCAHfTN3JcWTtSiuZ7QuKZvJg/cD8Lu4G/cuKGVK1fqxo0bcjqdGjlypMrLy+VwOFRcXKySkhJNmjRJBQUF+vzzzzVnzhxJ0vLlyzV27NiY/wcAsXDed7XfzL1vJn/ed9V2u3jgThx2+tJtRjRDg1zW2DWXZN9s5LImbiMaAMD9iYIHAENR8ABgKAoeAAxFwQOAoSh4ADAUBQ8AhqLgAcBQFDwAGIqCBwBDUfAAYCgKHgAMRcEDgKEoeAAwFAUPAIai4AHAUBQ8ABiKggcAQ1HwAGAoCh4ADEXBA4ChKHgAMBQFDwCGouABwFDDwi3o6enR6tWr1dLSosTERGVmZmrjxo1KTU3tt66srEzvv/++MjIyJElPP/20NmzYEJvUAICwwha8w+HQyy+/rOnTp0uSvF6v3nzzTb3xxhsD1hYWFmrNmjXRTwkAsCzsiMblcoXKXZKmTJmitra2mIYCANw7SzP4QCCgvXv3Kicn57aP19TUaN68eVq8eLGOHz8elYAAgMFxBIPBYKSLS0tL1dHRoR07dsjp7P93Q2dnp1wul4YPH676+nqtWrVKtbW1SklJiXpoAEB4YWfwfbxer5qbm1VeXj6g3CUpPT09dHvGjBlyu91qamrStGnTIg7T1dWrQCDiv29uee0kdXZes3xcrJHLGnJZZ9ds5LJmsLmcTofS0h658+ORPMn27dvV0NCgnTt3KjEx8bZrOjo6QrcbGxt18eJFjRs3zmJcAEC0hN3BNzU1qby8XFlZWVqwYIEkacyYMdq5c6eKi4tVUlKiSZMmadu2bTp58qScTqeGDx+urVu39tvVAwCGVtiCf/LJJ3X69OnbPrZnz57Qba/XG71UAIB7xjtZAcBQFDwAGIqCBwBDUfAAYCgKHgAMRcEDgKEoeAAwFAUPAIai4AHAUBQ8ABiKggcAQ1HwAGAoCh4ADEXBA4ChKHgAMBQFDwCGouABwFAUPAAYioIHAENR8ABgKAoeAAxFwQOAoSh4ADAUBQ8AhhoWbkFPT49Wr16tlpYWJSYmKjMzUxs3blRqamq/dX6/X5s3b9ann34qh8OhJUuWqKioKGbBAQB3F3YH73A49PLLL+vAgQOqqqrS2LFj9eabbw5YV1VVpZaWFtXV1Wnfvn0qKytTa2trTEIDAMILW/Aul0vTp08P3Z8yZYra2toGrKutrVVRUZGcTqdSU1OVm5ur/fv3RzctACBilmbwgUBAe/fuVU5OzoDHfD6fRo8eHbrvdrvV3t5+7wkBAIMSdgZ/q02bNmnEiBFatGhRTMKkpT0y6GPT05OimCR6yGUNuayzazZyWROLXBEXvNfrVXNzs8rLy+V0Dtz4u91utbW1afLkyZIG7ugj0dXVq0AgaOkY6eYPprPzmuXjYo1c1pDLOrtmI5c1g83ldDruujGOaESzfft2NTQ0aOfOnUpMTLztmrlz56qiokKBQEDd3d06ePCg8vLyLAcGAERH2IJvampSeXm5Ll26pAULFqigoEDLly+XJBUXF+vEiROSpIKCAo0ZM0Zz5szR888/r+XLl2vs2LGxTQ8AuKOwI5onn3xSp0+fvu1je/bsCd1OSEhQaWlp9JIBAO4J72QFAENR8ABgKAoeAAxFwQOAoSh4ADAUBQ8AhqLgAcBQFDwAGIqCBwBDUfAAYCgKHgAMRcEDgKEoeAAwFAUPAIai4AHAUBQ8ABiKggcAQ1HwAGAoCh4ADEXBA4ChKHgAMBQFDwCGouABwFAUPAAYKmzBe71e5eTk6KmnntKZM2duu6asrEzPPPOMCgoKVFBQoNLS0qgHBQBYMyzcglmzZulXv/qVfvnLX951XWFhodasWRO1YACAexO24LOzs4ciBwAgyqI2g6+pqdG8efO0ePFiHT9+PFpPCwAYJEcwGAxGsjAnJ0fl5eWaMGHCgMc6Ozvlcrk0fPhw1dfXa9WqVaqtrVVKSkrUAwMAIhN2RBOJ9PT00O0ZM2bI7XarqalJ06ZNs/Q8XV29CgQi+vvmG6+fpM7Oa5aPizVyWUMu6+yajVzWDDaX0+lQWtojd378XkL16ejoCN1ubGzUxYsXNW7cuGg8NQBgkMLu4Ddv3qy6ujpdvnxZL774olwul2pqalRcXKySkhJNmjRJ27Zt08mTJ+V0OjV8+HBt3bq1364eADD0Ip7BDwVGNEODXNbYNZdk32zkssbWIxoAgP1Q8ABgKAoeAAxFwQOAoSh4ADAUBQ8AhqLgAcBQFDwAGIqCBwBDUfAAYCgKHgAMRcEDgKEoeAAwFAUPAIai4AHAUBQ8ABiKggcAQ1HwAGAoCh4ADEXBA4ChKHgAMBQF/4D4+GizGpt7+v1aY3OPPj7aHKdEAGKNgn9AZLmTtbuyIVTyjc092l3ZoCx3cpyTAYiVYfEOgKHhyUzR0sKJ2l3ZoJbL11Vz5JyWFk6UJzMl3tEAxEjYHbzX61VOTo6eeuopnTlz5rZr/H6/SktLlZubq9mzZ6uioiLqQXHvPJkpeu4Hj2vfJ2f03A8ep9wBw4Ut+FmzZum9997T448/fsc1VVVVamlpUV1dnfbt26eysjK1trZGNSjuXWNzjw4fv6j5syfo8PGLA2byAMwStuCzs7Pldrvvuqa2tlZFRUVyOp1KTU1Vbm6u9u/fH7WQuHd9M/elhRO1aK4nNK6h5AFzReUkq8/n0+jRo0P33W632tvbo/HUiJLzvqv9Zu59M/nzvqtxTgYgVmx1kjUt7ZFBH5uenhTFJNFjl1y/mjex3/309CSlpydpZpzy3Ildfl7fZNdckn2zkcuaWOSKSsG73W61tbVp8uTJkgbu6CPV1dWrQCBo+bj09CR1dl6zfFyskcsaclln12zksmawuZxOx103xlEZ0cydO1cVFRUKBALq7u7WwYMHlZeXF42nBgAMUtiC37x5s2bOnKn29na9+OKL+tnPfiZJKi4u1okTJyRJBQUFGjNmjObMmaPnn39ey5cv19ixY2ObHABwV45gMGh9JhIjjGiGBrmssWsuyb7ZyGWNrUc0AAD7oeABwFAUPAAYioIHAENR8ABgKAoeAAxFwQOAoSh4ADAUBQ8AhqLgAcBQFDwAGIqCBwBDUfAAYCgKHgAMRcEDgKEoeAAwFAUPAIai4AHAUBQ8ABiKggcAQ1HwAGAoCh4ADEXBA4ChKHgAMNSwSBadO3dOa9eu1ZUrV+RyueT1epWVldVvTVlZmd5//31lZGRIkp5++mlt2LAh6oEBAJGJqOA3bNighQsXqqCgQH/5y1+0fv16/elPfxqwrrCwUGvWrIl6SACAdWFHNF1dXTp16pTy8/MlSfn5+Tp16pS6u7tjHg4AMHhhC97n82nUqFFKSEiQJCUkJCgjI0M+n2/A2pqaGs2bN0+LFy/W8ePHo58WABCxiEY0kViwYIF+/etfa/jw4aqvr9eyZctUW1urlJSUiJ8jLe2RQb9+enrSoI+NJXJZQy7r7JqNXNbEIlfYgne73ero6JDf71dCQoL8fr8uXbokt9v9jXDpodszZsyQ2+1WU1OTpk2bFnGYrq5eBQJBC/H7XjtJnZ3XLB8Xa+SyhlzW2TUbuawZbC6n03HXjXHYEU1aWpo8Ho+qq6slSdXV1fJ4PEpNTe23rqOjI3S7sbFRFy9e1Lhx4ywHBgBER0Qjmtdff11r167Vrl27lJycLK/XK0kqLi5WSUmJJk2apG3btunkyZNyOp0aPny4tm7d2m9XDwAYWhEV/Pjx41VRUTHg1/fs2RO63Vf6AGAnHx9tVpY7WZ7Mr88HNjb36Lzvqn76w8w4Jos93skKwGhZ7mTtrmxQY3OPpJvlvruyQVnu5Dgni72oXUUDAHbkyUzR0sKJ2l3ZoJbL11Vz5JyWFk7st6M3FTt4AMbzZKbouR88rn2fnNFzP3j8gSh3iYIH8ABobO7R4eMXNX/2BB0+fjE0rjEdBQ/AaH0z96WFE7Voric0rnkQSp6CB2C0876r/WbufTP5876rcU4We5xkBWC0210K6clMeSDm8OzgAcBQFDwAGIqCBwBDUfAAYCgKHgAMRcEDiIqPjzYPuLa8sblHHx9tjlMiUPDAfcauRfogf6iXXVHwwH3GrkV664d6/df+xtC7Rx+E683tijc6AfcZO3864q0f6jXv37NskelBxg4euA/Z9dMRH9QP9bIrCh64D9mxSB/kD/WyKwoecWXXE4Z2ZtcifZA/1MuuKHjElV1PGNqZXYv0pz/MHDAq8mSmGP+9p4M1FJsbTrIirux8wtCuHuRPRzRJ3+ZmaeFEpacn9fuXWbRQ8Ig7rrzAg2goNjeMaKKMmbJ1djxhCAyFWF8NRcFHGTNla+x6whAYCrHe3ERU8OfOndP8+fOVl5en+fPn6/z58wPW+P1+lZaWKjc3V7Nnz1ZFRUVUg36TXXfKvJvPGrueMARibSg2NxEV/IYNG7Rw4UIdOHBACxcu1Pr16wesqaqqUktLi+rq6rRv3z6VlZWptbU1akG/yc47Zbu+CcWOuPICD6qh2NyELfiuri6dOnVK+fn5kqT8/HydOnVK3d3d/dbV1taqqKhITqdTqampys3N1f79+6MW9JvsvFNmpgwgnKHY3IQteJ/Pp1GjRikhIUGSlJCQoIyMDPl8vgHrRo8eHbrvdrvV3t4etaC3Y8edMjNlAHZhq8sk09IesbT+//6/Tv33522aP3uCPv4/5/XD74/W5H9Lj1G6yPzPiXb97n//r1COmdlPyOX6tpparmhmelJcs90q3UZZbkUu6+yajVzWxCJX2IJ3u93q6OiQ3+9XQkKC/H6/Ll26JLfbPWBdW1ubJk+eLGngjj4SXV29CgSCEa29dac8M/sJPfHow/qP/zwW9zHNzEmPSZI6O68pPT1JnZ3X5B75LbknPabOzmtxy3Wrvlx2Qy7r7JqNXNYMNpfT6bjrxjjsiCYtLU0ej0fV1dWSpOrqank8HqWmpvZbN3fuXFVUVCgQCKi7u1sHDx5UXl6e5cCR4uoLALi7iEY0r7/+utauXatdu3YpOTlZXq9XklRcXKySkhJNmjRJBQUF+vzzzzVnzhxJ0vLlyzV27NiYBeft2gBwdxEV/Pjx4297XfuePXtCtxMSElRaWhq9ZACAe8I7WQHAUBQ8ABiKggcAQ9nqOnin0xGXY2OJXNaQyzq7ZiOXNYPJFe4YRzAYjOzCcwDAfYURDQAYioIHAENR8ABgKAoeAAxFwQOAoSh4ADAUBQ8AhqLgAcBQFDwAGMpWH1UwGOfOndPatWt15coVuVwueb1eZWVlxTWT1+vVgQMHdPHiRVVVVWnChAlxzdOnp6dHq1evVktLixITE5WZmamNGzcO+PKWeFi2bJlaW1vldDo1YsQIvfbaa/J4PPGOJUnasWOHysrKbPV7mZOTo8TERD300EOSpFWrVunHP/5xnFNJ//rXv/TGG2/ob3/7mx566CFNmTJFmzZtimum1tZWLV++PHT/2rVr6u3t1d///vc4prrp8OHDevvttxUMBhUIBLRixYrQd2pERfA+98ILLwQrKyuDwWAwWFlZGXzhhRfinCgYPHbsWLCtrS343HPPBU+fPh3vOCE9PT3Bo0ePhu7/4Q9/CP7ud7+LY6KvXb16NXT7k08+CRYWFsYxzdcaGhqCL730UvAnP/mJrX4v7fZnq8+mTZuCW7ZsCQYCgWAwGAx2dnbGOdFAmzdvDpaWlsY7RjAQCASzs7NDv4+NjY3BKVOmBP1+f9Re474e0XR1denUqVPKz8+XJOXn5+vUqVPq7u6Oa67s7OwB31lrBy6XS9OnTw/dnzJlitra2uKY6GtJSV9/4XBvb68cjvh/INSXX36pjRs3asOGDbbIY3fXr19XZWWlVq5cGfp5Pfroo3FO1d+XX36pqqoq/eIXv4h3FEmS0+nUtWs3v4v12rVrysjIkNMZvVq+r0c0Pp9Po0aNUkJCgqSb3yqVkZEhn89ni7GDnQUCAe3du1c5OTnxjhKybt061dfXKxgM6t133413HL399tv6+c9/HtOvnrwXq1atUjAY1NSpU/Xb3/5WycnJcc1z4cIFuVwu7dixQ5999pkefvhhrVy5UtnZ2XHNdatDhw5p1KhR+t73vhfvKHI4HHrrrbe0bNkyjRgxQtevX9c777wT1de4r3fwGLxNmzZpxIgRWrRoUbyjhGzZskV//etf9corr2jr1q1xzXL8+HGdOHFCCxcujGuOO3nvvff00Ucf6YMPPlAwGNTGjRvjHUlfffWVLly4oO9+97v685//rFWrVmnFihXq7e2Nd7SQDz74wDa796+++krvvPOOdu3apcOHD2v37t165ZVXdP369ai9xn1d8G63Wx0dHfL7/ZIkv9+vS5cu2XI8Yider1fNzc166623ovrPwWgpLCzUZ599pp6enrhlOHbsmL744gvNmjVLOTk5am9v10svvaQjR47ELdOt+v6MJyYmauHChfrHP/4R50TS6NGjNWzYsNDI9Pvf/75SUlJ07ty5OCe7qaOjQ8eOHdO8efPiHUWS1NjYqEuXLmnq1KmSpKlTp+rb3/62zp49G7XXsN//3RakpaXJ4/GourpaklRdXS2Px8N45i62b9+uhoYG7dy5U4mJifGOI+nm7Nbn84XuHzp0SCNHjpTL5YpbpiVLlujIkSM6dOiQDh06pMcee0x//OMf9aMf/Shumfr885//DM1tg8GgamtrbXHFUWpqqqZPn676+npJN69w6+rqUmZmZpyT3fThhx/q2WefVUpKSryjSJIee+wxtbe364svvpAknT17VpcvX9YTTzwRtde477/w4+zZs1q7dq2uXr2q5ORkeb1efec734lrps2bN6uurk6XL19WSkqKXC6Xampq4ppJkpqampSfn6+srCx961vfkiSNGTNGO3fujGuuy5cva9myZbpx44acTqdGjhypNWvW2GJO2icnJ0fl5eW2uEzywoULWrFihfx+vwKBgMaPH6/f//73ysjIiHc0XbhwQa+++qquXLmiYcOG6Te/+Y2effbZeMeSJOXl5WndunWaOXNmvKOEfPTRR9qzZ0/opHRJSYlyc3Oj9vz3fcEDAG7vvh7RAADujIIHAENR8ABgKAoeAAxFwQOAoSh4ADAUBQ8AhqLgAcBQ/x/rMSxnWuovhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.abs(rescaled_weights), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6590751278>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.semilogy(np.abs(rescaled_weights), 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that's not bad for after 10k its."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding pruning into the mix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = np.load('../../tests/data/burgers.npy', allow_pickle=True).item()\n",
    "X = np.transpose((data['t'].flatten(), data['x'].flatten()))\n",
    "y = np.real(data['u']).reshape((data['u'].size, 1))\n",
    "number_of_samples = 500\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "\n",
    "## Running DeepMoD\n",
    "config = {'input_dim': 2, 'hidden_dim': 20, 'layers': 5, 'output_dim': 1, 'library_function': library_basic, 'library_args':{'poly_order': 2, 'diff_order': 2}}\n",
    "\n",
    "X_input = create_deriv_data(X_train, config['library_args']['diff_order'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll add pruning into the mix. We need to build our own pruning method. For now we do it not very compact in the training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils import prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_network(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "threshold = 1e-4\n",
    "max_iterations = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only apply pruning after the mse has converged enough:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n",
      "       2000    100.00%               0s   1.51e-04   9.28e-05   5.78e-05   0.00e+00 "
     ]
    }
   ],
   "source": [
    "print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "for iteration in torch.arange(0, max_iterations + 1):\n",
    "    (prediction, time_deriv_list, theta), f = model(X_input)\n",
    "    loss_mse = torch.mean((prediction[0] - y_train)**2)\n",
    "    loss_reg = torch.mean((time_deriv_list[0] - f)**2)\n",
    "    loss = loss_mse + loss_reg\n",
    "    \n",
    "    # Writing\n",
    "    if iteration % 100 == 0:\n",
    "        progress(iteration, 0, max_iterations, loss.item(), loss_mse.item(), loss_reg.item(), 0)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0537, -0.3621,  0.2435, -0.2996, -0.8363,  0.5636,  0.4016,  0.0908,\n",
       "         -0.2901]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[-1].weight * torch.norm(theta, dim=0) / torch.norm(time_deriv_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00117483],\n",
       "       [-0.08605842],\n",
       "       [ 0.06933831],\n",
       "       [-0.00996884],\n",
       "       [-0.9838677 ],\n",
       "       [ 0.12882902],\n",
       "       [ 0.01307354],\n",
       "       [ 0.51698136],\n",
       "       [-0.13619334]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(theta.cpu().detach().numpy(), time_deriv_list[0].cpu().detach().numpy(), rcond=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "threshold = 5e-2\n",
    "max_iterations = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n",
      "       5000    100.00%               0s   4.31e-07   2.22e-07   2.09e-07   0.00e+00 "
     ]
    }
   ],
   "source": [
    "print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "for iteration in torch.arange(0, max_iterations + 1):\n",
    "    (prediction, time_deriv_list, theta), f = model(X_input)\n",
    "    loss_mse = torch.mean((prediction[0] - y_train)**2)\n",
    "    loss_reg = torch.mean((time_deriv_list[0] - f)**2)\n",
    "    loss = loss_mse + loss_reg\n",
    "    \n",
    "    # Writing\n",
    "    if iteration % 100 == 0:\n",
    "        progress(iteration, 0, max_iterations, loss.item(), loss_mse.item(), loss_reg.item(), 0)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    rescaled_weights = model[-1].weight * torch.norm(theta, dim=0) / torch.norm(time_deriv_list[0])\n",
    "    mask = torch.abs(rescaled_weights) > threshold\n",
    "    prune.custom_from_mask(model[-1], name='weight', mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False, False,  True, False,  True, False, False, False, False]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.        , -0.        ,  0.10001196, -0.        , -1.0006839 ,\n",
       "        0.        ,  0.        ,  0.        ,  0.        ], dtype=float32)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[-1].weight.cpu().detach().numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0000, -0.0000,  0.3870, -0.0000, -0.9944,  0.0000,  0.0000,  0.0000,\n",
       "          0.0000]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding l1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = np.load('../../tests/data/burgers.npy', allow_pickle=True).item()\n",
    "X = np.transpose((data['t'].flatten(), data['x'].flatten()))\n",
    "y = np.real(data['u']).reshape((data['u'].size, 1))\n",
    "number_of_samples = 500\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "\n",
    "## Running DeepMoD\n",
    "config = {'input_dim': 2, 'hidden_dim': 20, 'layers': 5, 'output_dim': 1, 'library_function': library_basic, 'library_args':{'poly_order': 2, 'diff_order': 2}}\n",
    "\n",
    "X_input = create_deriv_data(X_train, config['library_args']['diff_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_network(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "threshold = 1e-1\n",
    "l1 = 1e-5\n",
    "max_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n",
      "      10000    100.00%               0s   1.50e-05   5.65e-07   4.90e-07   1.40e-05 "
     ]
    }
   ],
   "source": [
    "print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "for iteration in torch.arange(0, max_iterations + 1):\n",
    "    (prediction, time_deriv_list, theta), f = model(X_input)\n",
    "    \n",
    "    loss_mse = torch.mean((prediction[0] - y_train)**2)\n",
    "    loss_reg = torch.mean((time_deriv_list[0] - f)**2)\n",
    "    rescaled_weights = model[-1].weight * torch.norm(theta, dim=0) / torch.norm(time_deriv_list[0])\n",
    "    loss_l1 = l1 * torch.sum(torch.abs(rescaled_weights))\n",
    "    loss = loss_mse + loss_reg + loss_l1\n",
    "    \n",
    "    # Writing\n",
    "    if iteration % 100 == 0:\n",
    "        progress(iteration, 0, max_iterations, loss.item(), loss_mse.item(), loss_reg.item(), loss_l1.item())\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if iteration > 5000:\n",
    "        mask = torch.abs(rescaled_weights) > threshold\n",
    "        prune.custom_from_mask(model[-1], name='weight', mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.0000,  0.4243, -0.0000, -0.9715, -0.0000, -0.0000, -0.0000,\n",
       "          0.0000]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rescaled_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
