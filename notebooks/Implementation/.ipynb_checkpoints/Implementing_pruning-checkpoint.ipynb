{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we implement an easier library layer, a regression layer and the pruning with pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Remainder imports\n",
    "from os import listdir, path, getcwd\n",
    "\n",
    "# Setting cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Defining output folder\n",
    "output_folder = getcwd()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# DeepMoD stuff\n",
    "from deepymod_torch.utilities import create_deriv_data\n",
    "from deepymod_torch.network import Linear, Tanh\n",
    "from deepymod_torch.output import progress\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing new layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a simpler library layer for now use in the network. Let's not worry about deepmod for now and just make it easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Library(nn.Module):\n",
    "    '''Abstract baseclass for library-as-layer. Child requires theta function (see library_functions). '''\n",
    "    def __init__(self, input_dim, output_dim, diff_order):\n",
    "        super().__init__()\n",
    "        self.diff_order = diff_order\n",
    "        self.total_terms = self.terms(input_dim, output_dim, self.diff_order)\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''Calculates output.'''\n",
    "        time_deriv_list, theta = self.theta(input)\n",
    "        return input, time_deriv_list, theta\n",
    "\n",
    "    def terms(self, input_dim, output_dim, max_order):\n",
    "        '''Calculates the number of terms the library produces'''\n",
    "        sample_data = (torch.ones((1, output_dim), dtype=torch.float32), torch.ones((1, max_order, input_dim, output_dim), dtype=torch.float32)) # we run a single forward pass on fake data to infer shapes\n",
    "        total_terms = self.theta(sample_data)[1].shape[1]\n",
    "\n",
    "        return total_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class library_basic(Library):\n",
    "    '''Implementation of library layer. Inherets from Library layer.'''\n",
    "    def __init__(self, input_dim, output_dim, diff_order, poly_order):\n",
    "        self.poly_order = poly_order\n",
    "        super().__init__(input_dim, output_dim, diff_order)\n",
    "    \n",
    "    def theta(self, input):\n",
    "        '''Calculates the library and time deriv from NN output'''\n",
    "        X, dX = input\n",
    "        samples = X.shape[0]\n",
    "\n",
    "        # Time derivatives\n",
    "        dt = dX[:, 0, :1, :]\n",
    "        time_deriv_list = torch.unbind(dt, dim=2)\n",
    "\n",
    "        # Polynomial part\n",
    "        u = torch.ones_like(X)[:, None, :]\n",
    "        for order in torch.arange(1, self.poly_order+1):\n",
    "            u = torch.cat((u, u[:, order-1:order, :] * X[:, None, :]), dim=1)\n",
    "        poly_list = torch.unbind(u, dim=2) #list with each entry corresponding to eq.\n",
    "\n",
    "        # Derivative part\n",
    "        dx = dX[:, :, 1:, :]\n",
    "        deriv_list = [torch.cat((torch.ones((samples, 1)), eq.reshape(samples, -1)), dim=1) for eq in torch.unbind(dx, dim=3)] #list with each entry corresponding to eq.\n",
    "        \n",
    "        # Combining to make  theta\n",
    "        if len(poly_list) == 1:\n",
    "            theta = torch.matmul(poly_list[0][:, :, None], deriv_list[0][:, None, :]).reshape(samples, -1) # If we have a single output, we simply calculate and flatten matrix product between polynomials and derivatives to get library\n",
    "        else:\n",
    "            theta_uv = torch.cat([torch.matmul(u[:, :, None], v[:, None, :]).reshape(samples, -1) for u, v in combinations(poly_list, 2)], 1)  # calculate all unique combinations between polynomials\n",
    "            theta_dudv = torch.cat([torch.matmul(du[:, :, None], dv[:, None, :]).reshape(samples, -1)[:, 1:] for du, dv in combinations(deriv_list, 2)], 1) # calculate all unique combinations of derivatives\n",
    "            theta_udu = torch.cat([torch.matmul(u[:, 1:, None], du[:, None, 1:]).reshape(samples, -1) for u, du in product(poly_list, deriv_list)], 1)  # calculate all unique products of polynomials and derivatives\n",
    "            theta = torch.cat([theta_uv, theta_dudv, theta_udu], dim=1)\n",
    "\n",
    "        return time_deriv_list, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regression layer is a simple linear layer, but we also need to forward the output so let's build a simple wrapper:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(nn.Linear):\n",
    "    '''Pytorch style linear layer which also calculates the derivatives w.r.t input. Has been written to be a thin wrapper around the pytorch layer. '''\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__(in_features, out_features, bias=False)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        '''Calculates output'''\n",
    "        X, time_deriv_list, theta = input\n",
    "        z = F.linear(theta, self.weight)\n",
    "        \n",
    "        return (X, time_deriv_list[0], z)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(input_dim, hidden_dim, layers, output_dim, library_function, library_args):\n",
    "    ''' Build deepmod model.'''\n",
    "    network = [Linear(input_dim, hidden_dim), Tanh()]  # Input layer\n",
    "    for hidden_layer in torch.arange(layers):  # Hidden layers\n",
    "        network.append(Linear(hidden_dim, hidden_dim))\n",
    "        network.append(Tanh())\n",
    "    network.append(Linear(hidden_dim, output_dim))  # Output layer\n",
    "    \n",
    "    network.append(library_function(input_dim, output_dim, **library_args)) # Library layer\n",
    "    network.append(Regression(network[-1].total_terms, 1)) # Regression layer\n",
    "    torch_network = nn.Sequential(*network)\n",
    "\n",
    "    return torch_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data\n",
    "data = np.load('../../tests/data/burgers.npy', allow_pickle=True).item()\n",
    "X = np.transpose((data['t'].flatten(), data['x'].flatten()))\n",
    "y = np.real(data['u']).reshape((data['u'].size, 1))\n",
    "number_of_samples = 500\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)\n",
    "\n",
    "## Running DeepMoD\n",
    "config = {'input_dim': 2, 'hidden_dim': 20, 'layers': 5, 'output_dim': 1, 'library_function': library_basic, 'library_args':{'poly_order': 2, 'diff_order': 2}}\n",
    "\n",
    "X_input = create_deriv_data(X_train, config['library_args']['diff_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_network(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.15 ms ± 2.5 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "model(X_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, time to train without l1 and pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "max_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n",
      "      10000    100.00%               0s   8.99e-07   5.34e-07   3.65e-07   0.00e+00 "
     ]
    }
   ],
   "source": [
    "print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "for iteration in torch.arange(0, max_iterations + 1):\n",
    "    prediction, time_deriv, f = model(X_input)\n",
    "    loss_mse = torch.mean((prediction[0] - y_train)**2)\n",
    "    loss_reg = torch.mean((time_deriv - f)**2)\n",
    "    loss = loss_mse + loss_reg\n",
    "        \n",
    "    # Writing\n",
    "    if iteration % 100 == 0:\n",
    "        progress(iteration, 0, max_iterations, loss.item(), loss_mse.item(), loss_reg.item(), 0)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's look at the weights..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-5.4734e-05, -7.3680e-04,  1.0283e-01, -5.2212e-03, -9.6069e-01,\n",
       "         -1.7441e-02,  1.7855e-02, -1.1310e-01,  3.9254e-02]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[-1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
