{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we implement a Bayesian version of DeepMoD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/opt/conda/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from deepmod_l1.analytical import theta_analytical\n",
    "\n",
    "#Plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# DeepMoD stuff\n",
    "from deepymod_torch.DeepMod import DeepMod, build_network\n",
    "from deepymod_torch.library_functions import library_basic\n",
    "from deepymod_torch.utilities import create_deriv_data\n",
    "from deepymod_torch.output import progress\n",
    "\n",
    "# Remainder imports\n",
    "from os import listdir, path, getcwd\n",
    "\n",
    "# Setting cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Defining output folder\n",
    "output_folder = getcwd()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('../../tests/data/burgers.npy', allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.transpose((data['t'].flatten(), data['x'].flatten()))\n",
    "y = np.real(data['u']).reshape((data['u'].size, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 1000\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adapting deepmod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just need to slightly modify the fitting layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Library(nn.Module):\n",
    "    '''Abstract baseclass for library-as-layer. Child requires theta function (see library_functions). '''\n",
    "    def __init__(self, input_dim, output_dim, diff_order):\n",
    "        super().__init__()\n",
    "        self.diff_order = diff_order\n",
    "        self.total_terms = self.terms(input_dim, output_dim, self.diff_order)\n",
    "\n",
    "    def forward(self, input):\n",
    "        '''Calculates output.'''\n",
    "        time_deriv_list, theta = self.theta(input)\n",
    "        return input, time_deriv_list, theta\n",
    "\n",
    "    def terms(self, input_dim, output_dim, max_order):\n",
    "        '''Calculates the number of terms the library produces'''\n",
    "        sample_data = (torch.ones((1, output_dim), dtype=torch.float32), torch.ones((1, max_order, input_dim, output_dim), dtype=torch.float32)) # we run a single forward pass on fake data to infer shapes\n",
    "        total_terms = self.theta(sample_data)[1].shape[1]\n",
    "\n",
    "        return total_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class library_basic(Library):\n",
    "    '''Implementation of library layer. Inherets from Library layer.'''\n",
    "    def __init__(self, input_dim, output_dim, diff_order, poly_order):\n",
    "        self.poly_order = poly_order\n",
    "        super().__init__(input_dim, output_dim, diff_order)\n",
    "    \n",
    "    def theta(self, input):\n",
    "        '''Calculates the library and time deriv from NN output'''\n",
    "        X, dX = input\n",
    "        samples = X.shape[0]\n",
    "\n",
    "        # Time derivatives\n",
    "        dt = dX[:, 0, :1, :]\n",
    "        time_deriv_list = torch.unbind(dt, dim=2)\n",
    "\n",
    "        # Polynomial part\n",
    "        u = torch.ones_like(X)[:, None, :]\n",
    "        for order in torch.arange(1, self.poly_order+1):\n",
    "            u = torch.cat((u, u[:, order-1:order, :] * X[:, None, :]), dim=1)\n",
    "        poly_list = torch.unbind(u, dim=2) #list with each entry corresponding to eq.\n",
    "\n",
    "        # Derivative part\n",
    "        dx = dX[:, :, 1:, :]\n",
    "        deriv_list = [torch.cat((torch.ones((samples, 1)), eq.reshape(samples, -1)), dim=1) for eq in torch.unbind(dx, dim=3)] #list with each entry corresponding to eq.\n",
    "        \n",
    "        # Combining to make  theta\n",
    "        if len(poly_list) == 1:\n",
    "            theta = torch.matmul(poly_list[0][:, :, None], deriv_list[0][:, None, :]).reshape(samples, -1) # If we have a single output, we simply calculate and flatten matrix product between polynomials and derivatives to get library\n",
    "        else:\n",
    "            theta_uv = torch.cat([torch.matmul(u[:, :, None], v[:, None, :]).reshape(samples, -1) for u, v in combinations(poly_list, 2)], 1)  # calculate all unique combinations between polynomials\n",
    "            theta_dudv = torch.cat([torch.matmul(du[:, :, None], dv[:, None, :]).reshape(samples, -1)[:, 1:] for du, dv in combinations(deriv_list, 2)], 1) # calculate all unique combinations of derivatives\n",
    "            theta_udu = torch.cat([torch.matmul(u[:, 1:, None], du[:, None, 1:]).reshape(samples, -1) for u, du in product(poly_list, deriv_list)], 1)  # calculate all unique products of polynomials and derivatives\n",
    "            theta = torch.cat([theta_uv, theta_dudv, theta_udu], dim=1)\n",
    "\n",
    "        return time_deriv_list, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting and running deepmod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'input_dim': 2, 'hidden_dim': 20, 'layers': 5, 'output_dim': 1, 'library_function': library_basic, 'library_args':{'poly_order': 2, 'diff_order': 2}}\n",
    "\n",
    "X_input = create_deriv_data(X_train, config['library_args']['diff_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_network(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we'll do PI training, we need a decent estimate, otherwise we'll get shite posteriors. (There's no noise for now anyway)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "max_iterations = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n",
      "       5000    100.00%               0s   2.71e-06   2.71e-06   0.00e+00   0.00e+00 "
     ]
    }
   ],
   "source": [
    "print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "for iteration in torch.arange(0, max_iterations + 1):\n",
    "    prediction, time_deriv_list, theta = model(X_input)\n",
    "    loss_mse = torch.mean((prediction[0] - y_train)**2)\n",
    "    loss = loss_mse \n",
    "        \n",
    "    # Writing\n",
    "    if iteration % 100 == 0:\n",
    "        progress(iteration, 0, max_iterations, loss.item(), loss_mse.item(), 0, 0)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that done, let's do a fit to see the result, both using least squares and bayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.7115453e-05],\n",
       "       [ 5.2083950e-03],\n",
       "       [ 9.2110246e-02],\n",
       "       [ 1.9702425e-03],\n",
       "       [-1.1246353e+00],\n",
       "       [ 5.5794012e-02],\n",
       "       [-4.1911104e-03],\n",
       "       [ 2.2810708e-01],\n",
       "       [-8.9375928e-02]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(theta.cpu().detach().numpy(), time_deriv_list[0].cpu().detach().numpy(), rcond=None)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which doesn't seem too bad. Now let's do some bayezzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type II maximalization on deepmod results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = theta.detach().clone()\n",
    "y = time_deriv_list[0].detach().clone()\n",
    "\n",
    "M = X.shape[1]\n",
    "N = X.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = nn.Parameter(torch.tensor(1.0))\n",
    "noise = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "optimizer = torch.optim.Adam([cov, noise])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2381.2461]], grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(0.1454, requires_grad=True) Parameter containing:\n",
      "tensor(0.0048, requires_grad=True)\n",
      "tensor([[-2381.2461]], grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(0.1454, requires_grad=True) Parameter containing:\n",
      "tensor(0.0048, requires_grad=True)\n",
      "tensor([[-2381.2461]], grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(0.1454, requires_grad=True) Parameter containing:\n",
      "tensor(0.0048, requires_grad=True)\n",
      "tensor([[-2381.2458]], grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(0.1454, requires_grad=True) Parameter containing:\n",
      "tensor(0.0048, requires_grad=True)\n",
      "tensor([[-2381.2461]], grad_fn=<MulBackward0>) Parameter containing:\n",
      "tensor(0.1454, requires_grad=True) Parameter containing:\n",
      "tensor(0.0048, requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for it in np.arange(5000):\n",
    "    alpha = 1/cov\n",
    "    beta = 1/noise**2\n",
    "    A = alpha * torch.eye(X.shape[1]) + beta * X.T @ X\n",
    "    mn = beta * torch.inverse(A) @ X.T @ y\n",
    "    E = beta/2 * (y - X @ mn).T @ (y - X @ mn) + alpha/2 * mn.T @ mn\n",
    "    \n",
    "    loss = -1 * (M/2*torch.log(alpha) + N/2 * torch.log(beta) - E - torch.sum(torch.log(torch.diag(torch.cholesky(A)))))\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if it %1000 == 0:\n",
    "        print(loss, cov, noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now get a the following means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.1631e-05],\n",
       "        [ 2.9984e-03],\n",
       "        [ 9.1805e-02],\n",
       "        [ 2.1081e-03],\n",
       "        [-1.1128e+00],\n",
       "        [ 5.6161e-02],\n",
       "        [-4.7116e-03],\n",
       "        [ 2.1575e-01],\n",
       "        [-8.9609e-02]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0003, 0.0072, 0.0036, 0.0048, 0.0357, 0.0189, 0.0116, 0.0382, 0.0212],\n",
       "       grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.diagonal(torch.inverse(A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which seems pretty similar to the other results :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing deepmod with bayesian inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we can just throw the bayesian loss in there with the mse. The massive difference in loss might be problematic though, but let's see. We also won't update the prior to be the previous posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params':[cov, noise]}])\n",
    "max_iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n",
      "       1000    100.00%               0s   -2.51e+03   3.53e-01   -2.51e+03   0.00e+00 "
     ]
    }
   ],
   "source": [
    "print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "for iteration in torch.arange(0, max_iterations + 1):\n",
    "    # NN\n",
    "    prediction, time_deriv_list, theta = model(X_input)\n",
    "    loss_mse = torch.mean((prediction[0] - y_train)**2)\n",
    "    \n",
    "    ## Bayes\n",
    "    alpha = 1/cov\n",
    "    beta = 1/noise**2\n",
    "    A = alpha * torch.eye(theta.shape[1]) + beta * theta.T @ theta\n",
    "    mn = beta * torch.inverse(A) @ theta.T @ time_deriv_list[0]\n",
    "    E = beta/2 * (time_deriv_list[0] - theta @ mn).T @ (time_deriv_list[0] - theta @ mn) + alpha/2 * mn.T @ mn\n",
    "    \n",
    "    loss_bayes = -1 * (M/2*torch.log(alpha) + N/2 * torch.log(beta) - E - torch.sum(torch.log(torch.diag(torch.cholesky(A)))))\n",
    "    \n",
    "    \n",
    "    # Full loss\n",
    "    loss = loss_mse + loss_bayes\n",
    "        \n",
    "    # Writing\n",
    "    if iteration % 100 == 0:\n",
    "        progress(iteration, 0, max_iterations, loss.item(), loss_mse.item(), loss_bayes.item(), 0)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0065],\n",
       "        [-0.2509],\n",
       "        [-0.0021],\n",
       "        [-0.0091],\n",
       "        [-0.1137],\n",
       "        [ 0.0441],\n",
       "        [-0.0232],\n",
       "        [ 0.0882],\n",
       "        [ 0.0974]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that doens't work, probably because its vastly different magnitudes. How should we scale them?? Maybe use a probabilistic fuction generator as well?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Bayes + MSE from the start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's add some noise (maybe cholesky fails when theres no noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 500\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples] + np.random.normal(scale=0.01, size=y[idx, :][:number_of_samples].shape), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'input_dim': 2, 'hidden_dim': 20, 'layers': 5, 'output_dim': 1, 'library_function': library_basic, 'library_args':{'poly_order': 2, 'diff_order': 2}}\n",
    "\n",
    "X_input = create_deriv_data(X_train, config['library_args']['diff_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = nn.Parameter(torch.tensor(1.0))\n",
    "noise = nn.Parameter(torch.tensor(1.0))\n",
    "\n",
    "model = build_network(**config)\n",
    "\n",
    "optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params':[cov, noise]}])\n",
    "max_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n",
      "      10000    100.00%               0s   -3.57e+00   4.02e-02   -3.61e+00   0.00e+00 "
     ]
    }
   ],
   "source": [
    "print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "for iteration in torch.arange(0, max_iterations + 1):\n",
    "    # NN\n",
    "    prediction, time_deriv_list, theta = model(X_input)\n",
    "    loss_mse = torch.mean((prediction[0] - y_train)**2)\n",
    "    \n",
    "    ## Bayes\n",
    "    M = theta.shape[1]\n",
    "    N = theta.shape[0]\n",
    "\n",
    "    alpha = 1/cov**2\n",
    "    beta = 1/noise**2\n",
    "    A = alpha * torch.eye(theta.shape[1]) + beta * theta.T @ theta\n",
    "    mn = beta * torch.inverse(A) @ theta.T @ time_deriv_list[0]\n",
    "    E = beta/2 * (time_deriv_list[0] - theta @ mn).T @ (time_deriv_list[0] - theta @ mn) + alpha/2 * mn.T @ mn\n",
    "    \n",
    "    loss_bayes = -1/N * (M/2*torch.log(alpha) + N/2 * torch.log(beta) - E - torch.sum(torch.log(torch.diag(torch.cholesky(A)))))\n",
    "    \n",
    "    \n",
    "    # Full loss\n",
    "    loss = loss_mse + loss_bayes\n",
    "        \n",
    "    # Writing\n",
    "    if iteration % 100 == 0:\n",
    "        progress(iteration, 0, max_iterations, loss.item(), loss_mse.item(), loss_bayes.item(), 0)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rescaling bayes loss with the number of samples definitely helps a lot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(0.0229, requires_grad=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor(-0.0269, requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe optimizing for the hyperparameters is not correct? Maybe optimize with set hyperparameters and then after optimize the hyperparameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing DeepMoD + Bayes with fixed hyperparams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 500\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'input_dim': 2, 'hidden_dim': 20, 'layers': 5, 'output_dim': 1, 'library_function': library_basic, 'library_args':{'poly_order': 2, 'diff_order': 2}}\n",
    "\n",
    "X_input = create_deriv_data(X_train, config['library_args']['diff_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = nn.Parameter(torch.tensor(0.1))\n",
    "noise = nn.Parameter(torch.tensor(0.0001))\n",
    "\n",
    "model = build_network(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "max_iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n",
      "      10000    100.00%               0s   1.97e-06   1.54e-06   4.26e-07   0.00e+00 "
     ]
    }
   ],
   "source": [
    "print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "for iteration in torch.arange(0, max_iterations + 1):\n",
    "    # NN\n",
    "    prediction, time_deriv_list, theta = model(X_input)\n",
    "    loss_mse = torch.mean((prediction[0] - y_train)**2)\n",
    "    \n",
    "    ## Bayes\n",
    "    M = theta.shape[1]\n",
    "    N = theta.shape[0]\n",
    "\n",
    "    alpha = 1/cov**2\n",
    "    beta = 1/noise**2\n",
    "    A = alpha * torch.eye(theta.shape[1]) + beta * theta.T @ theta\n",
    "    mn = beta * torch.inverse(A) @ theta.T @ time_deriv_list[0]\n",
    "    E = beta/2 * (time_deriv_list[0] - theta @ mn).T @ (time_deriv_list[0] - theta @ mn) + alpha/2 * mn.T @ mn\n",
    "    \n",
    "    loss_bayes = -10**-8/N * (M/2*torch.log(alpha) + N/2 * torch.log(beta) - E - torch.sum(torch.log(torch.diag(torch.cholesky(A)))))\n",
    "    \n",
    "    \n",
    "    # Full loss\n",
    "    loss = loss_mse + loss_bayes\n",
    "        \n",
    "    # Writing\n",
    "    if iteration % 100 == 0:\n",
    "        progress(iteration, 0, max_iterations, loss.item(), loss_mse.item(), loss_bayes.item(), 0)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3261e-04],\n",
       "        [-9.0307e-03],\n",
       "        [ 9.9883e-02],\n",
       "        [ 2.5409e-03],\n",
       "        [-9.4841e-01],\n",
       "        [-1.6438e-02],\n",
       "        [-1.2947e-02],\n",
       "        [-2.9883e-02],\n",
       "        [ 5.5709e-03]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.7857e-06, 1.5028e-04, 6.3782e-05, 1.2242e-04, 7.3811e-04, 3.1810e-04,\n",
       "        3.1361e-04, 8.6442e-04, 4.1129e-04], grad_fn=<SqrtBackward>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.diag(torch.inverse(A)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it doesn't necessarily blow up... The problem is in the scaling. Now let's see if we also train this model with the unleashed hyperparams;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params':[cov, noise]}])\n",
    "max_iterations = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n",
      "       5000    100.00%               0s   1.86e-07   2.42e-07   -5.56e-08   0.00e+00 "
     ]
    }
   ],
   "source": [
    "print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "for iteration in torch.arange(0, max_iterations + 1):\n",
    "    # NN\n",
    "    prediction, time_deriv_list, theta = model(X_input)\n",
    "    loss_mse = torch.mean((prediction[0] - y_train)**2)\n",
    "    \n",
    "    ## Bayes\n",
    "    M = theta.shape[1]\n",
    "    N = theta.shape[0]\n",
    "\n",
    "    alpha = 1/cov**2\n",
    "    beta = 1/noise**2\n",
    "    A = alpha * torch.eye(theta.shape[1]) + beta * theta.T @ theta\n",
    "    mn = beta * torch.inverse(A) @ theta.T @ time_deriv_list[0]\n",
    "    E = beta/2 * (time_deriv_list[0] - theta @ mn).T @ (time_deriv_list[0] - theta @ mn) + alpha/2 * mn.T @ mn\n",
    "    \n",
    "    loss_bayes = -10**-8/N * (M/2*torch.log(alpha) + N/2 * torch.log(beta) - E - torch.sum(torch.log(torch.diag(torch.cholesky(A)))))\n",
    "    \n",
    "    \n",
    "    # Full loss\n",
    "    loss = loss_mse + loss_bayes\n",
    "        \n",
    "    # Writing\n",
    "    if iteration % 100 == 0:\n",
    "        progress(iteration, 0, max_iterations, loss.item(), loss_mse.item(), loss_bayes.item(), 0)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.5640e-04],\n",
       "        [-8.7454e-03],\n",
       "        [ 9.3006e-02],\n",
       "        [-7.3255e-03],\n",
       "        [-9.6000e-01],\n",
       "        [ 2.5402e-02],\n",
       "        [ 1.6730e-02],\n",
       "        [-3.4320e-02],\n",
       "        [-2.9389e-02]], grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should rescale the covariance by the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3430],\n",
       "        [0.3621],\n",
       "        [0.0142],\n",
       "        [0.3568],\n",
       "        [0.0163],\n",
       "        [0.2614],\n",
       "        [0.4036],\n",
       "        [0.5377],\n",
       "        [0.2891]], grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt(torch.diag(torch.inverse(A)))[:, None]/torch.abs(mn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the terms we need are very sure :):)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try it from the beginning using the rescaled version and see what we get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combingin it all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = 1000\n",
    "\n",
    "idx = np.random.permutation(y.size)\n",
    "X_train = torch.tensor(X[idx, :][:number_of_samples], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(y[idx, :][:number_of_samples], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {'input_dim': 2, 'hidden_dim': 20, 'layers': 5, 'output_dim': 1, 'library_function': library_basic, 'library_args':{'poly_order': 2, 'diff_order': 2}}\n",
    "\n",
    "X_input = create_deriv_data(X_train, config['library_args']['diff_order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = nn.Parameter(torch.tensor(0.1))\n",
    "noise = nn.Parameter(torch.tensor(0.1))\n",
    "\n",
    "model = build_network(**config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam([{'params': model.parameters()}, {'params':[cov, noise]}])\n",
    "max_iterations = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |\n",
      "      15000    100.00%               0s   4.71e-07   5.20e-07   -4.85e-08   0.00e+00 "
     ]
    }
   ],
   "source": [
    "print('| Iteration | Progress | Time remaining |     Cost |      MSE |      Reg |       L1 |')\n",
    "for iteration in torch.arange(0, max_iterations + 1):\n",
    "    # NN\n",
    "    prediction, time_deriv_list, theta = model(X_input)\n",
    "    loss_mse = torch.mean((prediction[0] - y_train)**2)\n",
    "    \n",
    "    ## Bayes\n",
    "    M = theta.shape[1]\n",
    "    N = theta.shape[0]\n",
    "\n",
    "    alpha = 1/cov**2\n",
    "    beta = 1/noise**2\n",
    "    A = alpha * torch.eye(theta.shape[1]) + beta * theta.T @ theta\n",
    "    mn = beta * torch.inverse(A) @ theta.T @ time_deriv_list[0]\n",
    "    E = beta/2 * (time_deriv_list[0] - theta @ mn).T @ (time_deriv_list[0] - theta @ mn) + alpha/2 * mn.T @ mn\n",
    "    \n",
    "    loss_bayes = -10**-8/N * (M/2*torch.log(alpha) + N/2 * torch.log(beta) - E - torch.sum(torch.log(torch.diag(torch.cholesky(A)))))\n",
    "    \n",
    "    \n",
    "    # Full loss\n",
    "    loss = loss_mse + loss_bayes\n",
    "        \n",
    "    # Writing\n",
    "    if iteration % 100 == 0:\n",
    "        progress(iteration, 0, max_iterations, loss.item(), loss_mse.item(), loss_bayes.item(), 0)\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.3517643e-04],\n",
       "       [ 1.8476116e-02],\n",
       "       [ 1.0045571e-01],\n",
       "       [-2.5506459e-02],\n",
       "       [-1.1085676e+00],\n",
       "       [ 2.0357821e-02],\n",
       "       [ 7.2394311e-02],\n",
       "       [ 4.2113297e-02],\n",
       "       [ 1.5086494e-04]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu = mn.cpu().detach().numpy()\n",
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.4369316e-03],\n",
       "       [ 9.4561450e-02],\n",
       "       [ 8.3281171e-01],\n",
       "       [-1.6419685e-01],\n",
       "       [-2.4899046e+00],\n",
       "       [ 7.9998106e-02],\n",
       "       [ 2.3173441e-01],\n",
       "       [ 5.4589432e-02],\n",
       "       [ 3.8710330e-04]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_rescaled = (mn * torch.norm(theta, dim=0)[:, None]).cpu().detach().numpy()\n",
    "mu_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00019006],\n",
       "       [0.00481694],\n",
       "       [0.00217257],\n",
       "       [0.00319643],\n",
       "       [0.0234166 ],\n",
       "       [0.011016  ],\n",
       "       [0.00734997],\n",
       "       [0.02543892],\n",
       "       [0.01237231]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std = torch.sqrt(torch.diag(torch.inverse(A)))[:, None].cpu().detach().numpy()\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00601011],\n",
       "       [0.0246533 ],\n",
       "       [0.01801134],\n",
       "       [0.02057692],\n",
       "       [0.05259499],\n",
       "       [0.04328848],\n",
       "       [0.02352726],\n",
       "       [0.03297524],\n",
       "       [0.03174602]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_rescaled = (torch.sqrt(torch.diag(torch.inverse(A)))[:, None]* torch.norm(theta, dim=0)[:, None]).cpu().detach().numpy()\n",
    "std_rescaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.0814332e-01],\n",
       "       [ 2.6071197e-01],\n",
       "       [ 2.1627145e-02],\n",
       "       [-1.2531862e-01],\n",
       "       [-2.1123292e-02],\n",
       "       [ 5.4111886e-01],\n",
       "       [ 1.0152685e-01],\n",
       "       [ 6.0405904e-01],\n",
       "       [ 8.2009178e+01]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std / mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.0814332e-01],\n",
       "       [ 2.6071197e-01],\n",
       "       [ 2.1627147e-02],\n",
       "       [-1.2531860e-01],\n",
       "       [-2.1123294e-02],\n",
       "       [ 5.4111886e-01],\n",
       "       [ 1.0152685e-01],\n",
       "       [ 6.0405898e-01],\n",
       "       [ 8.2009178e+01]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_rescaled / mu_rescaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to recap, our basic implementation seems to work: \n",
    "1) Optimization over all variables seems to work but requires scaling\n",
    "2) Starting from beginning with rescaled seems to converge pretty slowly\n",
    "3) We observed that our model was most sure about the terms we require\n",
    "4) Correct minimum seems to ecist, stepwise and manual scaling into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
