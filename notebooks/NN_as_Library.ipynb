{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I explore how we can use a neural network to build and fit a library automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Plotting imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "# Remainder imports\n",
    "from os import listdir, path, getcwd\n",
    "\n",
    "# Setting cuda\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "\n",
    "# Settings for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Defining output folder\n",
    "output_folder = getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As testdata, we use a analytic input features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(x, t, D, a):\n",
    "    c = 1 / np.sqrt(2*np.pi*(2*D*t + a**2))*np.exp(-x**2/(2*a**2+4*D*t))\n",
    "    \n",
    "    return c\n",
    "\n",
    "def c_x(x, t, D, a):\n",
    "    c_x = -x/(a**2+2*D*t) * c(x, t, D, a)\n",
    "    return c_x\n",
    "\n",
    "\n",
    "def c_xx(x, t, D, a):\n",
    "    c_xx = -1/(a**2+2*D*t) * c(x, t, D, a) - x/(a**2+2*D*t) * c_x(x, t, D, a)\n",
    "    return c_xx\n",
    "    \n",
    "def c_t(x, t, D, a):\n",
    "    c_t = D * c_xx(x, t, D, a)\n",
    "    \n",
    "    return c_t\n",
    "\n",
    "def theta_analytical(x_grid, t_grid, D, a):\n",
    "    u = c(x_grid, t_grid, D, a).reshape(-1, 1) # Because numerical derivatives don't do at edge\n",
    "    u2 = u**2\n",
    "\n",
    "    u_x = c_x(x_grid, t_grid, D, a).reshape(-1, 1)\n",
    "    u_xx = c_xx(x_grid, t_grid, D, a).reshape(-1, 1)\n",
    "\n",
    "    u_t = c_t(x_grid, t_grid, D, a).reshape(-1, 1)\n",
    "    \n",
    "    theta_analytical = np.concatenate([np.ones_like(u), u, u**2, u_x, u_xx], axis=1)\n",
    "    time_deriv_analytical = u_t\n",
    "    \n",
    "    return time_deriv_analytical, theta_analytical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a library with 2nd order polynomial, 2nd order derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 0.5\n",
    "a = 0.25\n",
    "\n",
    "x = np.linspace(-5, 5, 500, dtype=np.float32)\n",
    "t = np.linspace(0, 5, 100, dtype=np.float32)\n",
    "x_grid, t_grid = np.meshgrid(x, t, indexing='ij')\n",
    "    \n",
    "# Analytical\n",
    "time_deriv, theta = theta_analytical(x_grid, t_grid, D, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 5)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we perform lstsquares we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.5972991e-17],\n",
       "       [-4.5536491e-16],\n",
       "       [-1.1071983e-16],\n",
       "       [ 5.0000000e-01]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(theta, time_deriv, rcond=None)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is the perfect answer :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by using a simple network to learn the weights; we simply feed the normal theta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(theta, dtype=torch.float32)\n",
    "y_train = torch.tensor(time_deriv, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(*[nn.Linear(5, 1, bias=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17594009637832642\n",
      "0.0024052285589277744\n",
      "6.84987535350956e-05\n",
      "1.9155568224960007e-05\n",
      "9.16057251743041e-06\n",
      "2.6868626719078748e-06\n",
      "3.506295342958765e-07\n",
      "1.1892629991905324e-08\n",
      "4.2385130127886583e-11\n",
      "9.458204517167907e-15\n"
     ]
    }
   ],
   "source": [
    "for it in np.arange(iterations):\n",
    "    prediction = model(X_train)\n",
    "    loss = torch.mean((prediction - y_train)**2)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.6433e-09,  1.7092e-07, -6.7046e-07, -4.7474e-14,  5.0000e-01]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is pretty close so that works :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.46011828e-17],\n",
       "       [ 5.43835810e-16],\n",
       "       [-8.11850587e-16],\n",
       "       [-2.69903132e-18],\n",
       "       [ 5.00000000e-01]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(theta, time_deriv, rcond=None)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Normalizing theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use a log-transform, we need to normalize theta between 0 and 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.min(theta, axis=0) #numerical accuracy\n",
    "b = np.max(theta, axis=0) - np.min(theta, axis=0)\n",
    "\n",
    "a[0] = 0.0\n",
    "b[0] = 1.0 # do not transform the constant column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_normalized = (theta - a) / b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_t = np.min(time_deriv, axis=0)\n",
    "b_t = np.max(time_deriv, axis=0) - np.min(time_deriv, axis=0) \n",
    "\n",
    "time_deriv_normalized = (time_deriv - a_t ) / (b_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(theta_normalized, dtype=torch.float32)\n",
    "y_train = torch.tensor(time_deriv_normalized, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(*[nn.Linear(5, 1, bias=False)])\n",
    "model[0].weight = nn.Parameter(torch.rand(model[0].weight.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47839516401290894\n",
      "0.000341961596859619\n",
      "0.00027726314147002995\n",
      "0.00020647943892981857\n",
      "0.00013973168097436428\n",
      "9.538280573906377e-05\n",
      "7.769828516757116e-05\n",
      "7.293147064046934e-05\n",
      "6.951551767997444e-05\n",
      "6.481952004833147e-05\n"
     ]
    }
   ],
   "source": [
    "for it in np.arange(iterations):\n",
    "    prediction = model(X_train)\n",
    "    loss = torch.mean((prediction - y_train)**2)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.5338,  0.0825, -0.4727,  0.0178,  0.2134]], requires_grad=True)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.8381045e-16, -2.2204460e-16,  7.3031858e-16,  1.6653345e-16,\n",
       "        1.0000000e+00], dtype=float32)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(theta_normalized, time_deriv_normalized, rcond=None)[0].squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So somehow its a lot harder to train the normalized theta?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it's a lot harder to train... Weird. Let's check out a different normalization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.mean(theta, axis=0) #numerical accuracy\n",
    "b = np.std(theta, axis=0)\n",
    "\n",
    "a[0] = 0.0\n",
    "b[0] = 1.0 # do not transform the constant column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_normalized = (theta - a) / b \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(theta_normalized, dtype=torch.float32)\n",
    "y_train = torch.tensor(time_deriv, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(*[nn.Linear(5, 1, bias=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2669551968574524\n",
      "0.0008319122134707868\n",
      "2.8883556524306186e-07\n",
      "1.757089347067739e-13\n",
      "1.229401661446668e-14\n",
      "5.381115610611845e-15\n",
      "1.41960445558775e-15\n",
      "3.4110318541418134e-16\n",
      "3.410790979147438e-16\n",
      "2.8027790829052764e-16\n"
     ]
    }
   ],
   "source": [
    "for it in np.arange(iterations):\n",
    "    prediction = model(X_train)\n",
    "    loss = torch.mean((prediction - y_train)**2)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-5.2047e-04,  5.0952e-09, -9.2259e-09,  3.3022e-15,  2.8208e-01]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-5.2046892e-04,  4.3055759e-09, -8.6046299e-09, -2.0071293e-17,\n",
       "        2.8207895e-01], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(theta_normalized, time_deriv, rcond=None)[0].squeeze()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.min(theta, axis=0) - 1e-6#numerical accuracy\n",
    "b = np.max(theta, axis=0) - np.min(theta, axis=0)\n",
    "\n",
    "a[0] = 0.0\n",
    "b[0] = 1.0 # do not transform the constant column\n",
    "\n",
    "theta_normalized = (theta - a) / b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_log = np.log(theta_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we would fit using least squares, we'd get the followin result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ],\n",
       "       [ 0.01808725],\n",
       "       [-0.02312976],\n",
       "       [-0.51521766],\n",
       "       [ 1.2450912 ]], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.lstsq(theta_log, time_deriv, rcond=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(theta_log, dtype=torch.float32)\n",
    "y_train = torch.tensor(time_deriv, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(*[nn.Linear(5, 1, bias=False)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.51873016357422\n",
      "0.13111130893230438\n",
      "0.0866071805357933\n",
      "0.06916070729494095\n",
      "0.06476349383592606\n",
      "0.06175614148378372\n",
      "0.05895283818244934\n",
      "0.056992314755916595\n",
      "0.05615696310997009\n",
      "0.05599471554160118\n"
     ]
    }
   ],
   "source": [
    "for it in np.arange(iterations):\n",
    "    prediction = model(X_train)\n",
    "    loss = torch.mean((prediction - y_train)**2)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the problematic part is in the min/max normalization. We need it for the Linear layer though, so after we make the features we should rescale again:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling / Log / Rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the min-max rescaling and log to get cross features, so we scale back theta after:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.min(theta[:, 1:], axis=0) - 1e-6#numerical accuracy\n",
    "b = np.max(theta[:, 1:], axis=0) - np.min(theta[:, 1:], axis=0)\n",
    "\n",
    "theta_normalized = (theta[:, 1:] - a) / b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_log = np.log(theta_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.min(theta[:, 1:], axis=0) - 1e-6#numerical accuracy\n",
    "b = np.max(theta[:, 1:], axis=0) - np.min(theta[:, 1:], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Linear):\n",
    "    '''Pytorch style linear layer which also calculates the derivatives w.r.t input. Has been written to be a thin wrapper around the pytorch layer. '''\n",
    "    def __init__(self, in_features, out_features, a, b):\n",
    "        super().__init__(in_features, out_features, bias=False)\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        \n",
    "    def forward(self, input):\n",
    "        '''Calculates output'''\n",
    "        z = F.linear(input, self.weight)\n",
    "        result = torch.exp(z)\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outer product layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the old way, we can implement everything using an outer product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class outer_product(nn.Module):\n",
    "    '''Pytorch style linear layer which also calculates the derivatives w.r.t input. Has been written to be a thin wrapper around the pytorch layer. '''\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.tril_indices = torch.triu_indices(row=5, col=5, offset=1)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        '''Calculates output'''\n",
    "        z = torch.matmul(input[:, :, None], input[:, None, :])[:, self.tril_indices[0], self.tril_indices[1]]#.reshape(input.shape[0], -1)\n",
    "        \n",
    "        #z_normed = z / torch.norm(z, dim=0)\n",
    "        \n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.mean(theta, axis=0) #numerical accuracy\n",
    "b = np.std(theta, axis=0)\n",
    "\n",
    "a[0] = 0.0\n",
    "b[0] = 1.0 # do not transform the constant column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_normed = (theta - a) /b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 5)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_normed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(theta_normed, dtype=torch.float32)\n",
    "y_train = torch.tensor(time_deriv , dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(*[outer_product(), nn.Linear(10, 1, bias=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.974159240722656\n",
      "0.0483686700463295\n",
      "0.012646198272705078\n",
      "0.007338393479585648\n",
      "0.0035581283736974\n",
      "0.0010924830567091703\n",
      "0.00017606733308639377\n",
      "2.0091471014893614e-05\n",
      "2.8423751246009488e-06\n",
      "1.66701184411977e-07\n"
     ]
    }
   ],
   "source": [
    "for it in np.arange(iterations):\n",
    "    prediction = model(X_train)\n",
    "    loss = torch.mean((prediction - y_train)**2)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.4642e-04, -3.5886e-04, -4.5668e-10,  2.8206e-01,  4.5419e-05,\n",
       "         -1.0931e-10,  1.6444e-06, -1.4913e-10,  6.6258e-06, -3.3704e-11]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-0.0006], requires_grad=True)"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feb80f09208>]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD7CAYAAACCEpQdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAASXElEQVR4nO3df2xd9XnH8bedSC1qwhZ5jkZSEkPBT6OFFUIjSkVbUS2s21ot1dpBBKRSOzZC/620rRMhogKxdtKktinJWm1KQUoRowqbADEmUakwWIsa1CKxh1+JA/kxXM8SpN1asL0/fIzvNSa+17nx8fX3/ZIi3/s933Pvcx9Fn3vu9xz79kxMTCBJKktv3QVIkhae4S9JBTL8JalAhr8kFcjwl6QCLa+7gBa8C9gMHAfGaq5FkrrFMuAc4MfAr2Zu7Ibw3wz8sO4iJKlLfQR4bOZgN4T/cYDR0V8wPt7+7yT09a1gZORkx4vqVvajmf2YZi+adXs/ent7WLXqPVBl6EzdEP5jAOPjE/MK/6l9Nc1+NLMf0+xFsyXSj1mXyz3hK0kFMvwlqUCGvyQVyPCXpAIZ/lowDz05xLNDo01jzw6N8tCTQzVVJJXL8NeCGTjnbO488MxbbwDPDo1y54FnGDjn7Jork8rTDZd6aonYsH4VO7Zu5M4Dz3DlJWt59OBRdmzdyIb1q+ouTSqOR/5aUBvWr+LKS9byr/9xmCsvWWvwSzUx/LWgnh0a5dGDR/nUhwd49ODRt50DkLQwDH8tmKk1/h1bN/Lpj57/1hKQbwDSwjP8tWAOH3+taY1/6hzA4eOv1VyZVB5P+GrB/MGH1r9tbMP6Va77SzXwyF+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFailP+kcEYPAPqAPGAG2Z+bzM+bcDFwDvFn9+3JmPlxt2wXcBByrpj+emV/sxAuQJLWv1SP/PcDuzBwEdgN7Z5nzI2BzZn4A+DxwT0Sc1bD9u5l5cfXP4JekGs0Z/hGxGtgE7K+G9gObIqK/cV5mPpyZv6zu/hToYfKTgiRpkWll2edc4GhmjgFk5lhEHKvGh99hn+3Ai5n5SsPYNRFxFXACuCUzn2in0L6+Fe1Mb9Lfv3Le+y5F9qOZ/ZhmL5ot5X50/GscI+JjwFeALQ3De4DbMvONiNgC3B8RGzJzpNXHHRk5yfj4RNv19PevZHj49bb3W6rsRzP7Mc1eNOv2fvT29pzyoLmVNf+XgbURsQyg+rmmGm8SEZcDdwNbMzOnxjPzRGa+Ud1+pNp3YxuvQ5LUQXOGf2a+CjwNbKuGtgEHM7NpySciNgP3AJ/JzJ/M2La24fbFwACQSJJq0eqyz43AvojYCYwyuaZPRDwI7MzMp4BvAWcBeyNiar/rM/NnwO0RcSkwBvy6Gj/RuZchSWpHS+Gfmf8FXDbL+B823N58iv0/N6/qJElnhL/hK0kFMvwlqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUDLW5kUEYPAPqAPGAG2Z+bzM+bcDFwDvFn9+3JmPlxtWwZ8HfgEMAHckZnf6dSLkCS1p9Uj/z3A7swcBHYDe2eZ8yNgc2Z+APg8cE9EnFVtuxa4ALgQuBzYFREDp1O4JGn+5gz/iFgNbAL2V0P7gU0R0d84LzMfzsxfVnd/CvQw+UkB4Grg25k5npnDwAHgsx2oX5I0D60s+5wLHM3MMYDMHIuIY9X48Dvssx14MTNfqe6vA4Yath+p9m9ZX9+KdqY36e9fOe99lyL70cx+TLMXzZZyP1pa829HRHwM+AqwpZOPOzJykvHxibb36+9fyfDw650spavZj2b2Y5q9aNbt/ejt7TnlQXMra/4vA2urk7ZTJ2/XVONNIuJy4G5ga2Zmw6YjwPqG++tm21+StDDmDP/MfBV4GthWDW0DDlZr92+JiM3APcBnMvMnMx7mXuCGiOitzhVsBe473eIlSfPT6rLPjcC+iNgJjDK5pk9EPAjszMyngG8BZwF7I2Jqv+sz82fAXcBlwNTlobdm5kudeQmSpHb1TEy0v46+wAaAQ675d4b9aGY/ptmLZt3ej4Y1//OAw2/bvtAFSZLqZ/hLUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCGf6SVCDDX5IKZPhLUoGWtzIpIgaBfUAfMAJsz8znZ8y5CrgduAj4RmZ+qWHbLuAm4Fg19HhmfvG0q5ckzUtL4Q/sAXZn5t0RcR2wF/j4jDkvATcAfwK8e5bH+G7jG4IkqT5zLvtExGpgE7C/GtoPbIqI/sZ5mflCZh4E3ux4lZKkjmrlyP9c4GhmjgFk5lhEHKvGh9t4rmuqpaETwC2Z+UQ7hfb1rWhnepP+/pXz3ncpsh/N7Mc0e9FsKfej1WWf07UHuC0z34iILcD9EbEhM0dafYCRkZOMj0+0/cT9/SsZHn697f2WKvvRzH5MsxfNur0fvb09pzxobuVqn5eBtRGxDKD6uaYab0lmnsjMN6rbj1T7bmx1f0lSZ80Z/pn5KvA0sK0a2gYczMyWl3wiYm3D7YuBASDbqlSS1DGtLvvcCOyLiJ3AKLAdICIeBHZm5lMRcQXwPeBsoCcirgG+kJkPA7dHxKXAGPBr4PrMPNHh1yJJalHPxET76+gLbAA45Jp/Z9iPZvZjmr1o1u39aFjzPw84/LbtC12QJKl+hr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFWh5K5MiYhDYB/QBI8D2zHx+xpyrgNuBi4BvZOaXGrYtA74OfAKYAO7IzO905BVIktrW6pH/HmB3Zg4Cu4G9s8x5CbgB+Nos264FLgAuBC4HdkXEQNvVSpI6Ys7wj4jVwCZgfzW0H9gUEf2N8zLzhcw8CLw5y8NcDXw7M8czcxg4AHz2tCqXJM1bK8s+5wJHM3MMIDPHIuJYNT7c4vOsA4Ya7h+p9m9ZX9+KdqY36e9fOe99lyL70cx+TLMXzZZyP1pa818MRkZOMj4+0fZ+/f0rGR5+/QxU1J3sRzP7Mc1eNOv2fvT29pzyoLmVNf+XgbXVSdupk7drqvFWHQHWN9xf1+b+kqQOmjP8M/NV4GlgWzW0DThYrd236l7ghojorc4VbAXua7dYSVJntLrscyOwLyJ2AqPAdoCIeBDYmZlPRcQVwPeAs4GeiLgG+EJmPgzcBVwGTF0eemtmvtTB1yFJakPPxET76+gLbAA45Jp/Z9iPZvZjmr1o1u39aFjzPw84/LbtC12QJKl+hr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFWh5K5MiYhDYB/QBI8D2zHx+xpxlwNeBTwATwB2Z+Z1q2y7gJuBYNf3xzPxiJ16AJKl9LYU/sAfYnZl3R8R1wF7g4zPmXAtcAFzI5JvEwYj498w8XG3/bmZ+qQM1S5JO05zLPhGxGtgE7K+G9gObIqJ/xtSrgW9n5nhmDgMHgM92slhJUme0cuR/LnA0M8cAMnMsIo5V48MN89YBQw33j1RzplwTEVcBJ4BbMvOJdgrt61vRzvQm/f0r573vUmQ/mtmPafai2VLuR6vLPqdrD3BbZr4REVuA+yNiQ2aOtPoAIyMnGR+faPuJ+/tXMjz8etv7LVX2o5n9mGYvmnV7P3p7e0550NzK1T4vA2urE7pTJ3bXVOONjgDrG+6vm5qTmScy843q9iPV+MYWX4MkqcPmDP/MfBV4GthWDW0DDlbr+o3uBW6IiN7qfMBW4D6AiFg7NSkiLgYGgDzt6iVJ89Lqss+NwL6I2AmMAtsBIuJBYGdmPgXcBVwGTF0CemtmvlTdvj0iLgXGgF8D12fmiQ69BklSm3omJtpfR19gA8Ah1/w7w340sx/T7EWzbu9Hw5r/ecDht21f6IIkSfUz/CWpQIa/JBXI8JekAhn+klQgw1+SCmT4S1KBDH9JKpDhL0kFMvwlqUCGvyQVyPCXpAIZ/pJUIMNfkgpk+EtSgQx/SSqQ4S9JBTL8JalAhr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kqkOEvSQUy/CWpQC2Ff0QMRsQTEfFc9fPCWeYsi4jdEfFiRLwQEX/WyrYz4aEnh3h2aLRp7NmhUR56cuhMPq11dInF0I/FUIN1lF1Hq0f+e4DdmTkI7Ab2zjLnWuAC4ELgcmBXRAy0sK3jBs45mzsPPPNW854dGuXOA88wcM7ZZ+opraOLLIZ+LIYarKPsOnomJiZOOSEiVgPPAX2ZORYRy4AR4MLMHG6Y9wDwT5n5z9X9bwJDmfm1U21rocYB4NDIyEnGx09da6OpZv3RFefxwGOH2LF1IxvWr2p5/06ZquPKS9by6MGjtddRdz8Wi8XQD/9vzF6H/WiuY7796O3toa9vBcB5wOGZ25e38BjnAkczcwygegM4Vo0PN8xbBzR+JjlSzZlrW0uqF9Gy/v6VHPn5L7jnkee4essgH/3gurb27xTrWJwWQz8WQw3WUW4drYT/ojCfI/8HHjvE1VsGeeCxQ6z7rffU9u79wGOH+NSHBxZFHXX3Y7FYDP3w/8bsddiP5jrm24+GI//Zt7fwGC8Da6vlHqqfa6rxRkeA9Q331zXMOdW2jpv6uLRj60au+8QGdmzd2LR+tlAa6/j0R89fFHXU2Y/FYjH0w/8b71yH/ViYfswZ/pn5KvA0sK0a2gYcbFzvr9wL3BARvRHRD2wF7mthW8cdPv5a0/rYhvWr2LF1I4ePv3amntI6ushi6MdiqME6yq5jzhO+ABHxfmAfsAoYBbZnZkbEg8DOzHyq+kTwTeCqare/zcx/qPZ/x20tGGAeJ3yn9PevZHj49bb3W6rsRzP7Mc1eNOv2fsx1wrel8K/ZAIZ/x9iPZvZjmr1o1u39mCv8/Q1fSSqQ4S9JBTL8JalA3XCd/zKYXL+ar9PZdymyH83sxzR70ayb+9FQ+7LZtnfDCd8rgB/WXYQkdamPAI/NHOyG8H8XsBk4DozVXIskdYtlwDnAj4FfzdzYDeEvSeowT/hKUoEMf0kqkOEvSQUy/CWpQIa/JBXI8JekAhn+klSgbvjzDvMWEYNMfg9BH5NfOr89M5+vt6qFFxF9wF3A+5j8ZY8XgL+Y5Qt5ihMRtwC7gIsy85may6lFRLwb+Hvg94D/A57IzD+vt6r6RMQnga8APUweIO/KzO/XW1XnLfUj/z3A7swcBHYDe2uupy4TwFczMzLzd4EXgTtqrql2EbEJ+BCTXzNasq8yGfqDmXkRcHPN9dQmInqYPFC6PjMvBq4D9kXEksvKJfeCpkTEamATsL8a2g9sqr5GsiiZ+T+Z+YOGoSdp/k7l4kTEu5g8ILiJyTfHIkXECmA7cHNmTgBk5n/XW1XtxoHfqG7/JnA8M8drrOeMWLLhD5wLHM3MMYDq57FqvFjVEcwO4F/qrqVmtwJ3Z+ahugup2fuYXBK9JSKeiogfRMQVdRdVl+oN8E+B+yNiCDgAfK7eqs6MpRz+mt03gJNMfqdykSLicib/WOC36q5lEVgOnA8czMwPAn8JfD8izq63rHpExHLgr4E/zsz1wKeAe6pPSEvKUg7/l4G11ZfHT32J/JpqvEgR8XfAhcDVS/FjbBs+BrwfOBQRh4H3Ag9HxFV1FlWTIeBNquXRzPxP4OfAYJ1F1ehiYE1mPg5Q/fwFsKHWqs6AJRv+mfkq8DSwrRraxuTRTZFXuETEbcClwNbMfNufdy1JZt6RmWsycyAzB4BXgN/PzH+rubQFl5k/Bx4FtsBbV8itZvKKsBK9Arw3IgIgIjYAv83kRRJLypL+k84R8X4mL/VcBYwyealn1lvVwouI3wGeAZ4D/rcaPpSZn66vqsWjOvr/ZMGXep4P/COTl0S/AfxNZj5Ub1X1iYhrgb9i8sQvwC2ZeaDGks6IJR3+kqTZLdllH0nSOzP8JalAhr8kFcjwl6QCGf6SVCDDX5IKZPhLUoEMf0kq0P8D0XeNSrlxpXEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model[1].weight.detach().numpy().squeeze(), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[0](X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(X_train)\n",
    "loss = torch.mean((prediction - y_train)**2)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7713e-06, -6.3450e-06, -2.4461e-09, -3.3424e-07,  9.5131e-06,\n",
       "         -1.4830e-08,  2.3276e-07, -2.4728e-08,  3.6570e-06,  6.2027e-11]])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would that look like without the standardization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(theta, dtype=torch.float32)\n",
    "y_train = torch.tensor(time_deriv , dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(*[outer_product(), nn.Linear(10, 1, bias=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43380165100097656\n",
      "0.00034165961551479995\n",
      "4.4629498006543145e-05\n",
      "2.2150792574393563e-05\n",
      "1.529714063508436e-05\n",
      "9.889851753541734e-06\n",
      "5.752701326855458e-06\n",
      "2.6801058083947282e-06\n",
      "9.649442063164315e-07\n",
      "3.724122734638513e-07\n"
     ]
    }
   ],
   "source": [
    "for it in np.arange(iterations):\n",
    "    prediction = model(X_train)\n",
    "    loss = torch.mean((prediction - y_train)**2)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-1.2561e-02,  6.3200e-02, -5.0558e-06,  5.0039e-01, -6.5717e-02,\n",
       "          2.7903e-05, -4.4397e-04, -2.3097e-05, -1.9441e-03, -4.7750e-07]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.0003], requires_grad=True)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feb810ef400>]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model[1].weight.detach().numpy().squeeze(), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(X_train)\n",
    "loss = torch.mean((prediction - y_train)**2)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.2028e-06,  8.3921e-06, -1.2907e-09, -1.0582e-06, -9.4064e-06,\n",
       "          1.5103e-08,  5.8082e-06, -2.1975e-08, -8.3757e-06, -3.2276e-08]])"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check it out with the norm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_normed = theta / np.linalg.norm(theta, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(theta_normed, dtype=torch.float32)\n",
    "y_train = torch.tensor(time_deriv , dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(*[outer_product(), nn.Linear(10, 1, bias=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11555866152048111\n",
      "0.07917913794517517\n",
      "0.07881996780633926\n",
      "0.07846277952194214\n",
      "0.07810704410076141\n",
      "0.07775254547595978\n",
      "0.07739928364753723\n",
      "0.07704717665910721\n",
      "0.0766962468624115\n",
      "0.07634644210338593\n"
     ]
    }
   ],
   "source": [
    "for it in np.arange(iterations):\n",
    "    prediction = model(X_train)\n",
    "    loss = torch.mean((prediction - y_train)**2)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-10.3311,  -9.9170,   0.1281,  10.2887,  -9.7190,   0.0757,   9.9080,\n",
       "          -0.0537,  10.2377,  -0.0164]], requires_grad=True)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([2.3428e-05], requires_grad=True)"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7feb80fd2940>]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(model[1].weight.detach().numpy().squeeze(), 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model(X_train)\n",
    "loss = torch.mean((prediction - y_train)**2)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.4373e-06,  1.4868e-05,  1.2068e-10, -2.2053e-05,  1.2161e-04,\n",
       "          1.6073e-10, -1.4671e-04, -9.8037e-11, -3.8687e-04, -2.6962e-11]])"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model[1].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
